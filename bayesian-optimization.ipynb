{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries & Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defined Utility Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_set(filename):\n",
    "    \"\"\"\n",
    "    Load a dataset from a CSV file using Pandas.\n",
    "\n",
    "    This function attempts to read a CSV file specified by the 'filename' parameter \n",
    "    and return it as a Pandas DataFrame. If the function encounters an error during \n",
    "    the file reading process (e.g., file not found, invalid file format), it catches \n",
    "    the exception, prints the error message, and returns None.\n",
    "\n",
    "    Parameters:\n",
    "    - filename (str): The path to the CSV file that needs to be loaded.\n",
    "\n",
    "    Returns:\n",
    "    - pandas.DataFrame: A DataFrame containing the data from the CSV file, or None \n",
    "                         if an error occurs during file reading.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        return pd.read_csv(filename)\t\n",
    "    except Exception as e:\n",
    "        print (e)\n",
    "\n",
    "\n",
    "def gbm_cl_bo(max_depth, max_features, learning_rate, n_estimators, subsample):\n",
    "    \"\"\"\n",
    "    Perform Gradient Boosting Classifier model evaluation with cross-validation.\n",
    "\n",
    "    This function takes hyperparameters for a Gradient Boosting Classifier,\n",
    "    creates a model with these parameters, and evaluates its performance using \n",
    "    cross-validation on a training dataset. The function returns the mean accuracy \n",
    "    score of the model over the cross-validation folds.\n",
    "\n",
    "    Parameters:\n",
    "    - max_depth (float): The maximum depth of the individual regression estimators. \n",
    "                         The value is rounded to the nearest integer.\n",
    "    - max_features (str or int): The number of features to consider when looking for \n",
    "                                 the best split. Can be an integer, float, string, or None.\n",
    "    - learning_rate (float): Learning rate shrinks the contribution of each tree by \n",
    "                             `learning_rate`.\n",
    "    - n_estimators (float): The number of boosting stages to be run. The value is \n",
    "                            rounded to the nearest integer.\n",
    "    - subsample (float): The fraction of samples to be used for fitting the individual \n",
    "                         base learners. If smaller than 1.0, this results in Stochastic \n",
    "                         Gradient Boosting.\n",
    "\n",
    "    Returns:\n",
    "    - score (float): The mean accuracy score of the model computed over cross-validation \n",
    "                     folds.\n",
    "\n",
    "    Note: This function assumes the existence of predefined `x_train` and `y_train` \n",
    "          datasets and uses a fixed random state for reproducibility.\n",
    "    \"\"\"\n",
    "    \n",
    "    params_gbm = {}\n",
    "    params_gbm['max_depth'] = round(max_depth)\n",
    "    params_gbm['max_features'] = max_features\n",
    "    params_gbm['learning_rate'] = learning_rate\n",
    "    params_gbm['n_estimators'] = round(n_estimators)\n",
    "    params_gbm['subsample'] = subsample\n",
    "    \n",
    "    accuracy_scorer = make_scorer(accuracy_score)\n",
    "    \n",
    "    scores = cross_val_score(GradientBoostingClassifier(random_state=123, **params_gbm),\n",
    "                                                                        x_train, \n",
    "                                                                        y_train, \n",
    "                                                                        scoring = accuracy_scorer, \n",
    "                                                                        cv=5\n",
    "                                                        ).mean()\n",
    "    \n",
    "    score = scores.mean()\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Data Source (Iris Flowers Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepallength</th>\n",
       "      <th>sepalwidth</th>\n",
       "      <th>petallength</th>\n",
       "      <th>petalwidth</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepallength  sepalwidth  petallength  petalwidth        class\n",
       "0          5.1         3.5          1.4         0.2  Iris-setosa\n",
       "1          4.9         3.0          1.4         0.2  Iris-setosa\n",
       "2          4.7         3.2          1.3         0.2  Iris-setosa\n",
       "3          4.6         3.1          1.5         0.2  Iris-setosa\n",
       "4          5.0         3.6          1.4         0.2  Iris-setosa"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the wine data set using load_wine()\n",
    "test_dataset = load_data_set(\"iris_dataset.csv\")\n",
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve Dataset Components, Encoder the Dependent Variable & Create Splits using Random Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instatiate the label encoder and fit the data\n",
    "label_encoder = LabelEncoder()\n",
    "test_dataset[\"class\"] = label_encoder.fit_transform(test_dataset[\"class\"])\n",
    "\n",
    "# Retrieve dataset components data and target\n",
    "X = test_dataset[['sepallength', 'sepalwidth', 'petallength', 'petalwidth']]\n",
    "y = test_dataset[\"class\"]\n",
    "\n",
    "# Create training sets using random distribution\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Search Space Parameters and Instantiate  Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | learni... | max_depth | max_fe... | n_esti... | subsample |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.9285   \u001b[0m | \u001b[0m0.616    \u001b[0m | \u001b[0m4.183    \u001b[0m | \u001b[0m0.8872   \u001b[0m | \u001b[0m133.8    \u001b[0m | \u001b[0m0.8591   \u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.9198   \u001b[0m | \u001b[0m0.1577   \u001b[0m | \u001b[0m3.157    \u001b[0m | \u001b[0m0.884    \u001b[0m | \u001b[0m96.71    \u001b[0m | \u001b[0m0.8675   \u001b[0m |\n",
      "| \u001b[95m3        \u001b[0m | \u001b[95m0.9289   \u001b[0m | \u001b[95m0.9908   \u001b[0m | \u001b[95m4.664    \u001b[0m | \u001b[95m0.8162   \u001b[0m | \u001b[95m126.9    \u001b[0m | \u001b[95m0.9242   \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.9198   \u001b[0m | \u001b[0m0.2815   \u001b[0m | \u001b[0m6.264    \u001b[0m | \u001b[0m0.8237   \u001b[0m | \u001b[0m85.18    \u001b[0m | \u001b[0m0.9802   \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.9198   \u001b[0m | \u001b[0m0.796    \u001b[0m | \u001b[0m8.884    \u001b[0m | \u001b[0m0.963    \u001b[0m | \u001b[0m149.4    \u001b[0m | \u001b[0m0.9155   \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.9285   \u001b[0m | \u001b[0m0.8156   \u001b[0m | \u001b[0m5.949    \u001b[0m | \u001b[0m0.8055   \u001b[0m | \u001b[0m111.8    \u001b[0m | \u001b[0m0.8211   \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.9198   \u001b[0m | \u001b[0m0.819    \u001b[0m | \u001b[0m7.884    \u001b[0m | \u001b[0m0.9131   \u001b[0m | \u001b[0m99.2     \u001b[0m | \u001b[0m0.9997   \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.9198   \u001b[0m | \u001b[0m0.1467   \u001b[0m | \u001b[0m7.308    \u001b[0m | \u001b[0m0.897    \u001b[0m | \u001b[0m108.4    \u001b[0m | \u001b[0m0.9456   \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.9198   \u001b[0m | \u001b[0m0.3296   \u001b[0m | \u001b[0m5.804    \u001b[0m | \u001b[0m0.8638   \u001b[0m | \u001b[0m146.3    \u001b[0m | \u001b[0m0.9837   \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.9198   \u001b[0m | \u001b[0m0.8157   \u001b[0m | \u001b[0m3.239    \u001b[0m | \u001b[0m0.9887   \u001b[0m | \u001b[0m146.5    \u001b[0m | \u001b[0m0.9613   \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.9285   \u001b[0m | \u001b[0m0.4865   \u001b[0m | \u001b[0m9.767    \u001b[0m | \u001b[0m0.8834   \u001b[0m | \u001b[0m102.3    \u001b[0m | \u001b[0m0.8033   \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.9289   \u001b[0m | \u001b[0m0.0478   \u001b[0m | \u001b[0m3.372    \u001b[0m | \u001b[0m0.8256   \u001b[0m | \u001b[0m82.34    \u001b[0m | \u001b[0m0.8453   \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.9285   \u001b[0m | \u001b[0m0.5485   \u001b[0m | \u001b[0m4.25     \u001b[0m | \u001b[0m0.8359   \u001b[0m | \u001b[0m90.47    \u001b[0m | \u001b[0m0.9366   \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.9198   \u001b[0m | \u001b[0m0.4743   \u001b[0m | \u001b[0m8.378    \u001b[0m | \u001b[0m0.9338   \u001b[0m | \u001b[0m110.9    \u001b[0m | \u001b[0m0.919    \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.9198   \u001b[0m | \u001b[0m0.467    \u001b[0m | \u001b[0m9.743    \u001b[0m | \u001b[0m0.8296   \u001b[0m | \u001b[0m143.5    \u001b[0m | \u001b[0m0.8996   \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.9289   \u001b[0m | \u001b[0m0.5966   \u001b[0m | \u001b[0m7.793    \u001b[0m | \u001b[0m0.8355   \u001b[0m | \u001b[0m140.5    \u001b[0m | \u001b[0m0.8964   \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.9289   \u001b[0m | \u001b[0m0.07865  \u001b[0m | \u001b[0m5.553    \u001b[0m | \u001b[0m0.8723   \u001b[0m | \u001b[0m113.0    \u001b[0m | \u001b[0m0.8359   \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.9289   \u001b[0m | \u001b[0m0.1835   \u001b[0m | \u001b[0m9.644    \u001b[0m | \u001b[0m0.9311   \u001b[0m | \u001b[0m89.45    \u001b[0m | \u001b[0m0.9856   \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m0.9198   \u001b[0m | \u001b[0m0.8434   \u001b[0m | \u001b[0m3.369    \u001b[0m | \u001b[0m0.8407   \u001b[0m | \u001b[0m141.1    \u001b[0m | \u001b[0m0.9348   \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.9198   \u001b[0m | \u001b[0m0.3043   \u001b[0m | \u001b[0m8.141    \u001b[0m | \u001b[0m0.9237   \u001b[0m | \u001b[0m94.73    \u001b[0m | \u001b[0m0.9604   \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m0.9107   \u001b[0m | \u001b[0m0.6084   \u001b[0m | \u001b[0m3.906    \u001b[0m | \u001b[0m0.822    \u001b[0m | \u001b[0m112.1    \u001b[0m | \u001b[0m0.8017   \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m0.9289   \u001b[0m | \u001b[0m0.4278   \u001b[0m | \u001b[0m5.788    \u001b[0m | \u001b[0m0.9216   \u001b[0m | \u001b[0m112.7    \u001b[0m | \u001b[0m0.8378   \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m0.9289   \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m6.641    \u001b[0m | \u001b[0m0.8      \u001b[0m | \u001b[0m113.1    \u001b[0m | \u001b[0m0.8      \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m0.9285   \u001b[0m | \u001b[0m0.8923   \u001b[0m | \u001b[0m6.161    \u001b[0m | \u001b[0m0.966    \u001b[0m | \u001b[0m114.2    \u001b[0m | \u001b[0m0.8148   \u001b[0m |\n",
      "=====================================================================================\n",
      "It takes 0.3 minutes\n"
     ]
    }
   ],
   "source": [
    "# Run Bayesian Optimization\n",
    "start = time.time()\n",
    "\n",
    "# Search space parameters\n",
    "params_gbm ={\n",
    "    'max_depth':(3, 10),\n",
    "    'max_features':(0.8, 1),\n",
    "    'learning_rate':(0.01, 1),\n",
    "    'n_estimators':(80, 150),\n",
    "    'subsample': (0.8, 1)\n",
    "}\n",
    "\n",
    "# Create an instance of bayesian optimizer\n",
    "optimizer = BayesianOptimization(gbm_cl_bo, params_gbm, random_state=111)\n",
    "optimizer.maximize(init_points=20, n_iter=4)\n",
    "\n",
    "print('It takes %s minutes' % round((time.time() - start)/60, 2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best hyperparameters obtained by the optimizer\n",
    "params_gbm = optimizer.max['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.9908053399845699,\n",
       " 'max_depth': 4.6640851773001595,\n",
       " 'max_features': 0.8162385318902423,\n",
       " 'n_estimators': 126.8720166772641,\n",
       " 'subsample': 0.9242485838801394}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_gbm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
